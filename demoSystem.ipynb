{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e571cbfc9aa408",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Rational Future Prediction\n",
    "Goal: create an LLM system that uses RAG in order to predict the next innovation in a particular field through time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5372bccbb9534",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Step 1: gather data for the vector database from a website containing \"timeline\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91ba9de7bf51f57a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:16:49.376665Z",
     "start_time": "2024-06-16T16:16:49.254211Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1881: First long-distance line, between\\nBoston and Providence, R.I. *[Note 5] 1908: AT&T President Theodore Vail sets a goal of Universal Service: providing\\nhigh-quality telephone service to any American who wants it. *[Note 5] 1915: AT&T engineers transmit speech across the Atlantic Ocean by wireless\\nradio. *[Note 5] 1917: Bell System engineers demonstrate oneway radiotelephone transmission from\\nairplane to ground. *[Note 5] 1919: AT&T introduces dial telephones. *[Note 5] 1923: AT&T longdistance lines connect stations in the first network-radio\\nbroadcast. *[Note 5] 1925: The Research and Engineering Departments of AT&T and the Western Electric\\nCompany are incorporated as ell Telephone Laboratories. *[Note 5] 1927: Wireless telephone service between New York and London. *[Note 5] 1927: Don Juan, the first fulllength movie with sound uses AT&T equipment and\\nthe next year, Warner Bros. produces The Jazz Singer with AT&T equipment. *[Note\\n5] 1947: Bell Labs scientists Shockley, Bardeen and Brattain invent the transistor.\\n*[Note 5] 1950: The first microwave relay system opens between New York and Chicago.\\n*[Note 5] 1951: Directdistance dialing begins, enabling customers to call long distance\\nwithout operator assistance. *[Note 5] 1954: Growing out of attempts to make a silicon transistor, the Solar Battery is\\ndeveloped by Bell Labs. *[Note 5] 1958: Bell Labs scientists Shawlow and Townes conceive basic principles of the\\nlaser. *[Note 5] 1964: Touch-Tone telephones introduced. *[Note 5] 1964: Picturephone attracts crowds at the New York World\\'s Fair. *[Note 5] 1965: \"Improved Mobile Telephone Service\" directly connects car phones to the\\nrest of AT&T\\'s network. *[Note 5] 1967: Toll-free 800 service debuts. *[Note 5] 1968: AT&T establishes \"911\" as the nationwide emergency telephone number.\\n*[Note 5] 1970: The FCC sets aside frequencies for mobile communications and AT&T proposes\\nbuilding the first high capacity cellulartelephone system, choosing Chicago as\\nthe test city. *[Note 5] 1977: AT&T designs and operates the world\\'s first commercial fiber-optic system.\\n*[Note 5] 1981: First cellular license. FCC authorizes AT&T\\'s \"Advanced Mobile Phone\\nService,\" a decade after AT&T\\'s initial application. *[Note 5] 1982: AT&T agrees to divest all wholly owned Bell operating companies\\' exchange\\noperations and two years later formal divestiture ends the Bell System. *[Note\\n5] 1987: Integrated Services Digital Network (ISDN) introduced, first method for\\nimplementing Information Superhighway. *[Note 5] 1992: AT&T becomes the first company ever to earn two Malcolm Baldrige Quality\\nAwards -both in the same year! *[Note 5] 1993: AT&T replaces Exxon as the most valuable company in the world, based on\\nmarket value of outstanding stock. *[Note 5] 1994: AT&T and McCaw merger completed. *[Note 5]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "r = requests.get(\"https://www.telephonetribute.com/timeline.html\")\n",
    "html = r.text\n",
    "clean_text = ' '.join(BeautifulSoup(html, \"html.parser\").stripped_strings)\n",
    "text = \"1881\"+clean_text.split(\"1881\")[4]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f8004c148aacf4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## To extract data in the format of ['year']: ['sentence describing innovation'], use a Mistral procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d352e83c0b600a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T21:13:56.811544Z",
     "start_time": "2024-06-22T21:13:52.350200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/devam/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f241802353d040f5af88ad73b3f04373"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8ea03b302b347b19b391bd692a3bb17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1653c47ed84409f97155c03accfa5ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92e56630f55a42608d0d3d2100815167"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "token = getpass.getpass(\"huggingface token\")\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-v0.1\", huggingfacehub_api_token=token)\n",
    "llm = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "330d5b0e15f9f33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:17:59.978103Z",
     "start_time": "2024-06-16T16:17:53.147281Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filteredText = llm.invoke(f\"Filter out data in the form of 'year':'sentence' from the following text document: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "409bb9a9d6248469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:28:34.002233Z",
     "start_time": "2024-06-16T16:28:33.993472Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2550"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filteredText.content\n",
    "open('data.txt', 'w').write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23783d4b7ee3c18b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: add the data to a vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c2536b07cf3b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T18:04:20.618214Z",
     "start_time": "2024-06-16T18:04:19.964988Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 67, which is longer than the specified 20\n",
      "Created a chunk of size 139, which is longer than the specified 20\n",
      "Created a chunk of size 81, which is longer than the specified 20\n",
      "Created a chunk of size 99, which is longer than the specified 20\n",
      "Created a chunk of size 38, which is longer than the specified 20\n",
      "Created a chunk of size 84, which is longer than the specified 20\n",
      "Created a chunk of size 135, which is longer than the specified 20\n",
      "Created a chunk of size 61, which is longer than the specified 20\n",
      "Created a chunk of size 151, which is longer than the specified 20\n",
      "Created a chunk of size 80, which is longer than the specified 20\n",
      "Created a chunk of size 74, which is longer than the specified 20\n",
      "Created a chunk of size 106, which is longer than the specified 20\n",
      "Created a chunk of size 104, which is longer than the specified 20\n",
      "Created a chunk of size 85, which is longer than the specified 20\n",
      "Created a chunk of size 39, which is longer than the specified 20\n",
      "Created a chunk of size 64, which is longer than the specified 20\n",
      "Created a chunk of size 101, which is longer than the specified 20\n",
      "Created a chunk of size 35, which is longer than the specified 20\n",
      "Created a chunk of size 74, which is longer than the specified 20\n",
      "Created a chunk of size 174, which is longer than the specified 20\n",
      "Created a chunk of size 80, which is longer than the specified 20\n",
      "Created a chunk of size 127, which is longer than the specified 20\n",
      "Created a chunk of size 151, which is longer than the specified 20\n",
      "Created a chunk of size 116, which is longer than the specified 20\n",
      "Created a chunk of size 109, which is longer than the specified 20\n",
      "Created a chunk of size 112, which is longer than the specified 20\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader('/Users/devam/PycharmProjects/rationalFuturePrediction/data.txt').load()\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=20, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b911cfc46092f9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T18:05:07.494622Z",
     "start_time": "2024-06-16T18:05:07.296396Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='1994: AT&T and McCaw merger completed.', metadata={'source': '/Users/devam/PycharmProjects/rationalFuturePrediction/data.txt'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "docs = retriever.invoke(\"What happened in 2004?\")\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ae4614c494dfbac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fetches appropriate data in edge-cases (not in the vector db, picks the latest choice, demonstrates that the system understands temporal relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c659cafacc7492",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 3: Create a vanilla agent that combines an LLM with the vector database. \n",
    "Assess this base agent's ability to predict \"already seen events\" through a measure of cosine similarity taking into account size of \"event chain\" (how many past events it can see).\n",
    "\n",
    "Also assess its time series forecasting ability by testing its ability to guess the year correctly (1), the next innovation (2), and both. \n",
    "\n",
    "Also assess \"event chain skips\": randomly ommitting a few events in a long chain, and seeing how that impacts the above measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724888161f852f6f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c5eb9c0bab45f8b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4: Fine-tune LLM on event chains from the RAG Database. \n",
    "Fine-tune LLM by using the above metric as a loss function. Given a series of steps in the chain, predict the next event. WE DON\"T WORRY ABOUT TREATING THE DATE SEPERATELY BECAUSE THE LLM DEMONSTRATES TEMPORAL REASONING WITH DATE AND CONTENT CONCATINATED BASED OFF OF THE PREVIOUS DESCRIPTION).\n",
    "\n",
    "Go through all the permutations. In a chain of 6, we can start with the first one, go all the way down, etc. Figure out a formal definition for this. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94cbb82f9512791",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 5: Create a refined agent that combines the fine-tuned LLM with the vector database. \n",
    "\n",
    "Assess this  agent's ability to predict \"already seen events\" through a measure of cosine similarity taking into account size of \"event chain\" (how many past events it can see).\n",
    "\n",
    "Also assess its time series forecasting ability by testing its ability to guess the year correctly (1), the next innovation (2), and both. \n",
    "\n",
    "Also assess \"event chain skips\": randomly ommitting a few events in a long chain, and seeing how that impacts the above measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb876528b86648be",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T21:27:44.115216Z",
     "start_time": "2024-06-22T21:27:44.104014Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "def temporalLoss(prediction, skip, topk):\n",
    "    return -topk * cosine_similarity(prediction,skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ee5b4fb53edd614f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
